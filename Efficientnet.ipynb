{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca96ed8c",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a623f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input, BatchNormalization, MaxPool2D\n",
    "import pickle\n",
    "import sys\n",
    "import cv2\n",
    "import gc # to delete used memory after running models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a82b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b30a242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1635472559894361\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4185718784\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18390997025480888405\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e20610",
   "metadata": {},
   "source": [
    "### Techniques to use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e502c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_smote = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842593c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_augmentation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9289dc5a",
   "metadata": {},
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580506a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"x.pickle\",\"rb\")\n",
    "x = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6d906b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(threshold=10)\n",
    "x[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d957d82",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224c02d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.15, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a17cd4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes:  9\n"
     ]
    }
   ],
   "source": [
    "#get the unique classes with set, and count them with len\n",
    "K = len(set(y_train))\n",
    "print(\"Unique classes: \", K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20831a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46201, 224, 224)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22fc6b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 8, 8, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b69bc",
   "metadata": {},
   "source": [
    "## Smote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ced9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping x_train to use Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22e29e4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "if(use_smote):\n",
    "    x_train_rows = len(x_train)\n",
    "    x_train_rows\n",
    "    x_train = x_train.reshape(x_train_rows,-1)\n",
    "    x_train.shape\n",
    "#----------------    \n",
    "    x_train_rows = len(x_train)\n",
    "    x_train = x_train.reshape(x_train_rows,-1)\n",
    "    #Majority Class counts: 29360\n",
    "#----------------   \n",
    "    number_samples = 10000 #29360\n",
    "\n",
    "    smote = SMOTE(sampling_strategy = {0:number_samples, 1:number_samples, 2:number_samples, 3:number_samples,\n",
    "         4:number_samples, 5:number_samples, 6:number_samples, 7:number_samples, 8:29360}, random_state= 4)\n",
    "    x_smote, y_smote = smote.fit_resample(x_train, y_train)\n",
    "    \n",
    "    print(x_smote.shape, x_smote[0].shape, y_smote.shape)\n",
    "#----------------\n",
    "    x_train = x_smote.reshape(-1,45,45)\n",
    "    y_train = y_smote\n",
    "    print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733928ce",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2a788cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not connected to a TPU runtime. Using CPU/GPU strategy\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "    print(\"Device:\", tpu.master())\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n",
    "    strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b1e6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ef608eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " img_augmentation (Sequentia  (None, 224, 224, 3)      0         \n",
      " l)                                                              \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, 9)                4061100   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,061,100\n",
      "Trainable params: 4,019,077\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "with strategy.scope():\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = img_augmentation(inputs)\n",
    "    outputs = EfficientNetB0(include_top=True, weights=None, classes=K)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "254028de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d21c8d",
   "metadata": {},
   "source": [
    "## Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aade34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataGenerator requires 4 dimensions, including the color (greyscale or colored images)\n",
    "if(use_data_augmentation):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 45, 45,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27d41dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(use_data_augmentation):\n",
    "    batch_size = 16\n",
    "    data_generator = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, \n",
    "                                                                     horizontal_flip = True, vertical_flip = True,)\n",
    "                                                                     #rotation_range = 180,\n",
    "                                                                     #fill_mode = 'constant')\n",
    "    train_generator = data_generator.flow(x_train,y_train,batch_size)\n",
    "    steps_per_epoch = x_train.shape[0]//batch_size # divided twice by batch_size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb39c4",
   "metadata": {},
   "source": [
    "## Fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dfffd30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Used with the Data Augmentation segment:\n",
    "\n",
    "if(use_data_augmentation):\n",
    "    history = model.fit(train_generator, validation_data = [x_test, y_test], steps_per_epoch = steps_per_epoch, epochs = 100,\n",
    "                 callbacks = [callback])\n",
    "    \n",
    "# 0.9189 val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c976d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used normally without Data Augmentation Segment:\n",
    "#x_train = x_train.reshape(, 224, 224, 3)\n",
    "\n",
    "if(not use_data_augmentation):\n",
    "    history = model.fit(#x,y,\n",
    "                        x_train, y_train, validation_data = [x_test,y_test], \n",
    "                        epochs= 50, verbose = 2, callbacks=[callback], batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40427f",
   "metadata": {},
   "source": [
    "## Graphing the accuracies and losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70389f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2b8d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23495c48",
   "metadata": {},
   "source": [
    "## Evaluating model with training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79593211",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The way to measure the model performance\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def evaluation_measurement(y_valid, y_pred, num_classes=9, output_fig=False):\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    thresh ={}\n",
    "    mcauc = []\n",
    "    for i in range(num_classes):    \n",
    "        fpr[i], tpr[i], thresh[i] = roc_curve(y_valid, y_pred[:, i], pos_label=i)\n",
    "        auc_score = roc_auc_score(y_valid, y_pred, multi_class = 'ovr')  #'ovr'\n",
    "        mcauc.append(auc_score)\n",
    "\n",
    "    plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
    "    plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
    "    plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
    "    plt.plot(fpr[3], tpr[3], linestyle='--',color='yellow', label='Class 3 vs Rest')\n",
    "    plt.title('Multiclass ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    print(\"MCAUC= \", np.mean(mcauc))\n",
    "    \n",
    "    if output_fig:\n",
    "        plt.savefig('Multiclass ROC', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc93f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514361af",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_measurement(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b69ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606db949",
   "metadata": {},
   "source": [
    "## Opening pickle with data for predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef08a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"x_to_predict.pickle\",\"rb\")\n",
    "x_testing = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ee972",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4dc79",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f84e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = model.predict(x_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58fb04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954edccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3edf3",
   "metadata": {},
   "source": [
    "## Uploading CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bff521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for uploading\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pred_df = pd.DataFrame(predictions, columns = [\"Type 0\", \"Type 1\", \"Type 2\", \"Type 3\", \"Type 4\", \"Type 5\", \"Type 6\", \"Type 7\", \"Type 8\"])\n",
    "#pred_df['Id'] = pred_df.reset_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef035fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22358c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('./uploads/#Efficientnet.csv',index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637035b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x,y, x_train, y_train, x_test, y_test, pred_df, history, model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2e060",
   "metadata": {},
   "source": [
    "# -------------------------------------------------- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-alex",
   "language": "python",
   "name": "tf-alex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
